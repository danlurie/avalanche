{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function to compute Avalanche images\n",
    "\n",
    "Expects full file path to resting state 4D nifti image\n",
    "Currently, output images will be written to wd\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import absolute_import, division, print_function\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import os as os\n",
    "from scipy.ndimage.measurements import label\n",
    "from scipy.stats import zscore\n",
    "from nilearn.masking import compute_epi_mask\n",
    "from nilearn.masking import apply_mask\n",
    "from nilearn.masking import unmask\n",
    "from scipy.ndimage.morphology import generate_binary_structure\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load EPI data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "func_file = '/Users/dlurie/Dropbox/Projects/avalanche/avalanche/data/ds000133/sub-01/post/sub-01_ses-post_task-rest_run-01_bold_space-MNI152NLin2009cAsym_clean_std_fwhm6.nii.gz'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mask_file = '/Users/dlurie/Dropbox/Projects/avalanche/avalanche/data/ds000133/sub-01/post/sub-01_ses-post_task-rest_run-01_bold_space-MNI152NLin2009cAsym_brainmask.nii.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def avalanche(func_file, mask_file, thresh, connectivity, out_dir):\n",
    "    \"\"\"\n",
    "    Load and preprocess data.\n",
    "    \"\"\"\n",
    "    # Load the functional image.\n",
    "    func_img = nib.load(func_file)\n",
    "    func_data = func_img.get_data()\n",
    "    \n",
    "    if mask_file is not None:\n",
    "        # Load the mask image.\n",
    "        mask_img = nib.load(mask_file)\n",
    "    else:\n",
    "        # Create a new brain mask from the EPI data.\n",
    "        mask_img = compute_epi_mask(func_img)    \n",
    "    \n",
    "    # Mask the functional data\n",
    "    func_data_masked = apply_mask(func_img, mask_img)\n",
    "    \n",
    "    # Z-score the masked functional data.\n",
    "    func_data_masked_z = zscore(func_data_masked, axis=0)\n",
    "    \n",
    "    \"\"\"\n",
    "    Create the initial point-process image and 4D cluster image.\n",
    "    \"\"\"\n",
    "    # Apply the threshold and get the point-process data.\n",
    "    pp_data_masked = func_data_masked_z >= thresh\n",
    "    \n",
    "    # Unmask the point-process data, creating an image, and save it.\n",
    "    pp_img = unmask(pp_data_masked, mask_img)\n",
    "    pp_img.to_filename(os.path.join(out_dir,'{0}_thresh-{1}_conn-{2}_ppimage.nii.gz'.format(os.path.basename(func_file)[:-7], str(thresh), str(connectivity))))\n",
    "    \n",
    "    # Label 3D and 4D clusters.\n",
    "    struct = generate_binary_structure(4,connectivity)\n",
    "    pp_data = pp_img.get_data()\n",
    "    cluster_data, num_clusters = label(pp_data, struct)\n",
    "    \n",
    "    # Create a cluster image and save it.\n",
    "    cluster_img = nib.Nifti1Image(cluster_data, pp_img.affine)\n",
    "    cluster_img.to_filename(os.path.join(out_dir,'{0}_thresh-{1}_conn-{2}_clusterimage.nii.gz'.format(os.path.basename(func_file)[:-7], str(thresh), str(connectivity))))    \n",
    "    \n",
    "    \"\"\"\n",
    "    Remove clusters that only exist in a single volume.\n",
    "    \"\"\"\n",
    "    # Get the dimensions of the functional image.\n",
    "    (n_x, n_y, n_z, n_t) = cluster_img.shape\n",
    "   \n",
    "    # Mask the cluster image to get a 2D array.\n",
    "    cluster_data_masked = apply_mask(cluster_img, mask_img)\n",
    "    \n",
    "    # Initialize a matrix to count unique clusters in each volume.\n",
    "    uMat = np.zeros(shape=(num_clusters, n_t))\n",
    "    \n",
    "    # loop through each time point and identify cluster members:\n",
    "    for i in range(n_t):\n",
    "        #determine uniques at this time point:\n",
    "        inds = np.unique(cluster_data_masked[i,:])\n",
    "        #Note: 0 will always be a unique value, and we don't\n",
    "        #actually care about zeros, so ignore them:\n",
    "        uMat[(inds[1:].astype('int')-1),i] = 1\n",
    "        \n",
    "    #now the uMat matrix is populated with indicators for each of the \"avalanches\"\n",
    "    #but we need to determine which are truly avalanches (i.e., occur in more than\n",
    "    #one time point), and which are not\n",
    "    avarray= np.zeros((uMat.shape[0], n_t+1))\n",
    "    #fill this with binary data:\n",
    "    avarray[:,1:]= uMat\n",
    "    #and take the difference:\n",
    "    avarray[:,1:] = np.diff(avarray, axis=1)\n",
    "    #and then take it again to identify 1 to -1 (diff==-2) points - these are not \n",
    "    #avalanches!!!\n",
    "    tmparray = np.diff(avarray, axis=1)\n",
    "    \n",
    "    #now we can efficiently remove all fake avalanches:\n",
    "    fakes = np.asarray(np.where(np.sum(tmparray==-2,axis=1)))+1\n",
    "    cluster_data[np.isin(cluster_data,fakes)]=0 \n",
    "    \n",
    "    #now single time point clusters should be removed\n",
    "    #and we want to regenerate our labels:\n",
    "    cluster_data, num_clusters = label(cluster_data, struct)\n",
    "    \n",
    "    # Create an image from the new cluster data (now avalanche data) and then save it.\n",
    "    cluster_img = nib.Nifti1Image(cluster_data, header=func_img.header, affine=func_img.affine)\n",
    "    cluster_img.to_filename(os.path.join(out_dir,'{0}_thresh-{1}_conn-{2}_avalancheimage.nii.gz'.format(os.path.basename(func_file)[:-7], str(thresh), str(connectivity)))) \n",
    "    \n",
    "    \"\"\"\"\n",
    "    \n",
    "    img_new = nb.Nifti1Image(labeled_array, header=img.header, affine=img.affine)\n",
    "    \n",
    "    # Reconstruct the 4D volume\n",
    "    ava_file = os.path.join(os.getcwd(), 'avalancheLabels.nii.gz')\n",
    "    img_new.to_filename(ava_file)\n",
    "        \n",
    "    #make a new 4D array that is 1 time point greater than original data:\n",
    "    transition_array = np.zeros((n_x, n_y, n_z, n_t+1))\n",
    "    \n",
    "    #the point process should come from the de-faked avalance data:\n",
    "    signal = labeled_array\n",
    "    signal[signal>0]=1\n",
    "    #fill this transition array with binary data and leave first time point (t[0])\n",
    "    #empty:\n",
    "    transition_array[:,:,:,1:] = signal\n",
    "    \n",
    "    #take the difference between points across the 4th (time) dimension:\n",
    "    onset_array = np.diff(transition_array, axis=3)\n",
    "    onset_array[onset_array==-1] = 0\n",
    "    #the onset array is back in the same time order and number of time points\n",
    "    #as the original arrays...\n",
    "    \n",
    "    img_new = nb.Nifti1Image(onset_array, header=img.header, affine=img.affine)\n",
    "    # Reconstruct the 4D volume\n",
    "    pp_file = os.path.join(os.getcwd(), 'binary_pp.nii.gz')\n",
    "    img_new.to_filename(pp_file)\n",
    "\n",
    "    Nvoxels = np.unique(labeled_array, return_counts='true')\n",
    "    Nvoxels = np.asarray(Nvoxels).T\n",
    "    #get rid of the 0 count (these aren't avalanches)\n",
    "    Nvoxels = Nvoxels[1:]\n",
    "    \n",
    "    #could return num_features, Nvoxels\n",
    "    \n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for thresh in [1, 1.5, 2, 2.5]:\n",
    "    for struct in [1, 2, 3, 4]:\n",
    "        avalanche(func_file, mask_file, thresh, struct, '/Users/dlurie/Dropbox/Projects/avalanche/avalanche/data/ds000133/results/')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
